{"name":"Tupelo","tagline":"A language-agnostic tuplespace for distribution of computation and storage.","body":"Tupelo\r\n==\r\n\r\nTupelo is a language-agnostic tuplespace for coordination of distributed programs. It is designed for distribution of both computation and storage, on disk and in memory, with pluggable storage adapters. Its programming model is small and semantically transparent: there are tuples (built from arrays, hashes, and scalars), a few operations on tuples (read, write, take), and transactions composed of these operations. This data-centric model, unlike RPC and most forms of messaging, decouples application endpoints from each other, not only in space and time, but also in referential structure: processes refer to data rather than to other processes.\r\n\r\nTupelo is inspired by Masatoshi Seki's Rinda in the Ruby standard library, which in turn is based on David Gelernter's Linda. The programming models of Tupelo and Rinda are similar, except for the lack of transactions in Rinda. However, the implementations of the two are nearly opposite in architectural approach.\r\n\r\nThis repository contains the reference implementation in Ruby, with documentation, tests, benchmarks, and examples. Implementations in other languages must communicate with this one.\r\n\r\n\r\nDocumentation\r\n============\r\n\r\nIntroductory\r\n------------\r\n* [Tutorial](doc/tutorial.md)\r\n* [Examples](example)\r\n* [FAQ](doc/faq.md)\r\n\r\nIn Depth\r\n--------\r\n* [Transactions](doc/transactions.md)\r\n* [Replication](doc/replication.md)\r\n* [Subspaces](doc/subspace.md)\r\n* [Tuple stores](doc/tuplestores.md)\r\n* [Causality](doc/causality.md)\r\n* [Concurrency](doc/concurrency.md)\r\n\r\nBig Picture\r\n-----------\r\n* [Comparisons](doc/compare.md)\r\n* [Planned future work](doc/future.md)\r\n\r\nInternals\r\n---------\r\n* [Architecture](doc/arch.md)\r\n* [Protocols](doc/protocol.md)\r\n\r\nTalk\r\n----\r\n* [Abstract](sfdc.md) and [slides](doc/sfdc.pdf) for San Francisco Distributed Computing meetup, December 2013.\r\n\r\n\r\nGetting started\r\n==========\r\n\r\n1. Install ruby 2.0 or 2.1 (not 1.9) from http://ruby-lang.org. Examples and tests will not work on Windows (they use fork and unix sockets) or JRuby, though probably the underying libs will (using tcp sockets on Windows).\r\n\r\n2. Install the gem and its dependencies (you may need to `sudo` this):\r\n\r\n        gem install tupelo\r\n\r\n3. Try running tup:\r\n\r\n        $ tup\r\n        >> w [\"hello\", \"world\"]\r\n        >> ra\r\n        => [[\"hello\", \"world\"]]\r\n        >> t [nil, nil]\r\n        => [\"hello\", \"world\"]\r\n\r\n4. Take a look at the [FAQ](doc/faq.md), the [tutorial](doc/tutorial.md), and the many [examples](example).\r\n\r\n\r\nApplications\r\n=======\r\n\r\nTupelo is a flexible base layer for various distributed programming patterns and techniques, which are explored in the examples: job queues, shared configuration and state, load balancing, service discovery, in-memory data grids, message queues, publish/subscribe, dataflow, map-reduce, and both optimistic and pessimistic (lock/lease) concurrency control.\r\n\r\nTupelo can be used to impose a unified transactional structure and distributed access model on a mixture of programs and languages (polyglot computation) and a mixture of data stores (polyglot persistence), with consistent replication.\r\n\r\nSee the [example section](#examples) below and the [examples](example) directory.\r\n\r\n\r\nLimitations\r\n===========\r\n\r\nBottleneck\r\n----------\r\n\r\nThe main limitation of tupelo is that, except for read-only operations, **all tuple operations pass through a single process**, the message sequencer.\r\n\r\nThe sequencer has minimal state and minimal computation. The state is just a counter and the network connections (no storage of tuples or other application data). The computation is just counter increment and message dispatch (no transaction execution or searches). A transaction requires just one message (possibly with many recipients) to pass through the sequencer. The message sequencer can be light and fast.\r\n\r\nNevertheless, this process is a bottleneck. Each message traverses two hops, to and from the sequencer. Each tupelo client must be connected to the sequencer to transact on tuples (aside from local reads).\r\n\r\n**Tupelo will always have this limitation.** It is essential to the design of the system. By accepting this cost, we get some benefits, discussed in the next section.\r\n\r\nClients may communicate other data over side channels that do not go through the sequencer. For [example](example/socket-broker.rb), they can use the tuplespace to coordinate task assignments, data locations (perhaps external to the tuplespace), TCP hosts and ports, and other metadata, and then use direct connections for the data. The archiver, which is a special client that brings newly connected clients up to date, is another example of direct client-to-client connections.\r\n\r\nOther limitations\r\n-----------------\r\n\r\nThe message sequencer is also a SPoF (single point of failure), but this is not inherent in the design. A future version of tupelo will have options for failover or clustering of the sequencer, perhaps based on [raft](http://raftconsensus.github.io), with a cost of increased latency and complexity. (However, redundancy and failover of *application* data and computation *is* supported by the current implementation; app data and computations are distributed among the client processes.)\r\n\r\nThere are some limitations that may result from naive application of tupelo: high client memory use, high bandwidth use, high client cpu use. These resource issues can often be controlled with [subspaces](doc/subspace.md) and specialized data structures and data stores. There are several examples addressing these problems. Another approach is to use the tuplespace for low volume references to high volume data.\r\n\r\nAlso, see the discussion in [transactions](doc/transactions.md) on limitations of transactions across subspaces. It's likely that these limitations will soon be lifted, at the cost of increased latency (only for cross-subspace transactions).\r\n\r\nThis implementation is also limited in efficiency because of its use of Ruby.\r\n\r\nFinally, it must be understood that work on tupelo is still in early, experimental stages. **The tupelo software should not yet be relied on for applications where failure resistance and recovery are important.** The current version is suited for things like batch processing (especially complex dataflow topologies), which can be restarted after failure, or other distributed systems that have short lifespans or are disposable.\r\n\r\n\r\nBenefits\r\n========\r\n\r\nAs noted above, the sequencer assigns an incrementing sequence number, or *tick*, to each transaction and dispatches it to the clients, who take on all the burden of tuple computation and storage. This design choice leads to:\r\n\r\n* strong consistency: all clients have the same view of the tuplespace at a given tick of the global clock;\r\n\r\n* deterministic transaction execution across processes: transactions complete in two network hops, and transactions reference concrete tuples, not templates or queries that require further searching;\r\n\r\n* high concurrency: no interprocess locking or coordination is needed to prepare or execute transactions;\r\n\r\n* efficient distribution of transaction workload off of the critical path: transaction preparation (finding matching tuples) is performed by just the client initiating the transaction, and transaction execution is performed only by clients that subscribe to subspaces relevant to the transaction;\r\n\r\n* client-side logic within transactions: any client state can be accessed while preparing a transaction, and each client is free to use any template and search mechanism (deterministic or not), possibly taking advantage of the client's specialized tuple storage;\r\n\r\n* zero-latency reads: clients store subscribed tuples locally, so searching and waiting for matching tuples are local operations;\r\n\r\n* relatively easy data replication: all subscribers to a subspace replicate that subspace, possibly with different storage implementations;\r\n\r\n* even though storage is distributed, the client programming model is that all tuples are in the same place at the same time; there is no need to reason about multiple clocks or clock skew;\r\n\r\n* the current state of the tuplespace can be computed from an earlier state by replaying the transactions in sequence;\r\n\r\n* the evolution of system state over time is observable, and tupelo provides the tools to do so: the `--trace` switch, the `#trace` api, and the `tspy` program.\r\n\r\nAdditional benefits (not related to message sequencing) include:\r\n\r\n* the `tup` program for interactively starting and connecting to tupelo instances;\r\n\r\n* a framework for starting and controlling child and remote processes connected to the tuplespace;\r\n\r\n* options to tunnel connections over ssh and through firewalls, for running in public clouds and other insecure environments;\r\n\r\n* choice of object serialization method (msgpack, json, marshal, yaml);\r\n\r\n* choice of UNIX or TCP sockets.\r\n\r\nProcess control and tunneling are available independently of tupelo using the easy-serve gem.\r\n\r\n\r\nExamples\r\n========\r\n\r\nDistributed processing\r\n----------------------\r\n\r\nThis program counts prime numbers in an interval by distributing the problem to a set of hosts:\r\n\r\n    require 'tupelo/app/remote'\r\n\r\n    hosts = %w{itchy scratchy lisa bart} # ssh hosts with key-based auth\r\n\r\n    Tupelo.tcp_application do\r\n      hosts.each do |host|\r\n        remote host: host, passive: true, eval: %{\r\n          require 'prime' # ruby stdlib for prime factorization\r\n          loop do\r\n            _, input = take([\"input\", Integer])\r\n            write [\"output\", input, input.prime_division]\r\n          end\r\n        }\r\n      end\r\n\r\n      local do\r\n        inputs = 1_000_000_000_000 .. 1_000_000_000_200\r\n\r\n        inputs.each do |input|\r\n          write [\"input\", input]\r\n        end\r\n\r\n        count = 0\r\n        inputs.size.times do |i|\r\n          _, input, factors = take [\"output\", Integer, nil]\r\n          count += 1 if factors.size == 1 and factors[0][1] == 1\r\n          print \"\\rChecked #{i}\"\r\n        end\r\n\r\n        puts \"\\nThere are #{count} primes in #{inputs}\"\r\n      end\r\n    end\r\n\r\nSsh is used to set up the remote processes. Additionally, with the `--tunnel` command line argument, all tuple communication is tunneled over ssh. More examples like this are in [example/map-reduce](example/map-reduce), [example/pregel](example/pregel), and [example/parallel.rb](example/parallel.rb).\r\n\r\nDistributed storage\r\n-------------------\r\n\r\nHere's an example that creates an in-memory sqlite in one client with a table for Points of Interest (POI). A second client populates that table by writing POI tuples and then executes a SQL delete by writing a tuple with the deletion parameters.\r\n\r\n    require 'tupelo/app'\r\n    require_relative 'poi-client' # run this in example/sqlite\r\n\r\n    Tupelo.application do\r\n      local do\r\n        POISPACE = PoiStore.define_poispace(self)\r\n        define_subspace(\"cmd\", {id: nil, cmd: String, arg: nil})\r\n        define_subspace(\"rsp\", {id: nil, result: nil})\r\n      end\r\n\r\n      child PoiClient, poispace: POISPACE, subscribe: \"cmd\", passive: true do\r\n        loop do\r\n          req = take subspace(\"cmd\")\r\n          case req[:cmd]\r\n          when \"delete box\"\r\n            lat = req[:arg][:lat]; lng = req[:arg][:lng]\r\n            template = PoiTemplate.new(poi_template: subspace(\"poi\"),\r\n              lat: lat[0]..lat[1], lng: lng[0]..lng[1])\r\n            deleted = []\r\n            transaction do\r\n              while poi = take_nowait(template)\r\n                deleted << poi\r\n              end\r\n            end\r\n            write id: req[:id], result: deleted\r\n          end\r\n        end\r\n      end\r\n\r\n      child subscribe: \"rsp\" do\r\n        write lat: 1.2, lng: 3.4, desc: \"foo\"\r\n        write lat: 5.6, lng: 7.8, desc: \"bar\"\r\n        write lat: 1.3, lng: 3.5, desc: \"baz\"\r\n\r\n        write id: 1, cmd: \"delete box\", arg: {lat: [1.0, 1.4], lng: [3.0, 4.0]}\r\n        rsp = take id: 1, result: nil\r\n        log \"deleted: #{rsp[\"result\"]}\"\r\n      end\r\n    end\r\n\r\nThe output should be something like this:\r\n\r\n    A: client 3: deleted: [{\"lat\"=>1.2, \"lng\"=>3.4, \"desc\"=>\"foo\"}, {\"lat\"=>1.3, \"lng\"=>3.5, \"desc\"=>\"baz\"}]\r\n\r\nSee [example/sqlite](example/sqlite) for the complete example. More advanced versions of this example have remote, replicated sqlites for redundancy and load distribution.\r\n\r\nWeb app coordination\r\n--------------------\r\n\r\nThis example runs several sinatra web apps and uses tupelo to set up a chat network between their users.\r\n\r\n    require 'tupelo/app'\r\n    require 'sinatra/base'\r\n\r\n    Tupelo.application do\r\n      [9001, 9002, 9003].each do |port|\r\n        child do |client|\r\n          Class.new(Sinatra::Base).class_eval do\r\n            post '/send' do\r\n              client.write [\"message\", params[\"dest\"], params[\"text\"]]\r\n            end\r\n\r\n            get '/recv' do\r\n              \"%s for %s: %s\\n\" %\r\n                (client.take [\"message\", params[\"dest\"], String])\r\n            end\r\n\r\n            set :port, port\r\n            run!\r\n          end\r\n        end\r\n      end\r\n    end\r\n\r\nYou can use curl to chat:\r\n\r\n    $ curl 'localhost:9001/send?text=hello&dest=fred' -d ''\r\n\r\nand\r\n\r\n    $ curl 'localhost:9003/recv?dest=fred'\r\n    message for fred: hello\r\n\r\nNote that the `recv` call waits for a message if none is available.\r\n\r\nSee also [example/multi-tier](example/multi-tier) and the chat server in [example/chat](example/chat).\r\n\r\n\r\nDevelopment\r\n===========\r\n\r\nPatches and bug reports are most welcome.\r\n\r\nThis project is hosted at https://github.com/vjoel/tupelo\r\n\r\nDependencies\r\n------------\r\n\r\nGems that were developed to support this project:\r\n\r\n* https://github.com/vjoel/atdo\r\n\r\n* https://github.com/vjoel/easy-serve\r\n\r\n* https://github.com/vjoel/funl\r\n\r\n* https://github.com/vjoel/object-stream\r\n\r\n* https://github.com/vjoel/object-template\r\n\r\nOther gems:\r\n\r\n* msgpack\r\n\r\n* yajl-ruby (only used to support --json option)\r\n\r\n* nio4r (optional dependency of funl)\r\n\r\nOptional gems for some of the examples:\r\n\r\n* sinatra, json, http, sequel, sqlite, rbtree, leveldb-native, lmdb\r\n\r\nContact\r\n=======\r\n\r\nJoel VanderWerf, vjoel@users.sourceforge.net, [@JoelVanderWerf](https://twitter.com/JoelVanderWerf).\r\n\r\nLicense and Copyright\r\n========\r\n\r\nCopyright (c) 2013-2014, Joel VanderWerf\r\n\r\nLicense for this project is BSD. See the COPYING file for the standard BSD license. The supporting gems developed for this project are similarly licensed.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}